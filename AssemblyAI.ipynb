{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "586z69135BKd"
      },
      "source": [
        "# **Importing AssemblyAI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BIALW2tz4lx9",
        "outputId": "3a4953c9-0ac8-419c-da1f-35a870ee2f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting assemblyai\n",
            "  Downloading assemblyai-0.28.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.19.0 (from assemblyai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.10.7,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from assemblyai) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.10/dist-packages (from assemblyai) (4.12.2)\n",
            "Collecting websockets>=11.0 (from assemblyai)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.19.0->assemblyai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.19.0->assemblyai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.19.0->assemblyai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.10.7,>=1.7.0->assemblyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.10.7,>=1.7.0->assemblyai) (2.18.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.19.0->assemblyai) (1.2.1)\n",
            "Installing collected packages: websockets, h11, httpcore, httpx, assemblyai\n",
            "Successfully installed assemblyai-0.28.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install assemblyai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW1dAYvX48Qr"
      },
      "source": [
        "# **Transcript And Timestamp**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oFnctTr4tfJ",
        "outputId": "9c55d0d6-2db2-425a-c5da-8cd22574b867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "हेलो मीटर बिजली का आ जाइए सर। कहा आरोप है सर ये मकान आपका. ये उत्तम नगर में है। सिर उत्तम. नगर में ही कहाँ पर है? उत्तम नगर में रोड, उत्तम नगर में ग्रोवर स्वीट्स के सामने वाला ग्रोवर है। मेन रोड पर मेन रोड पे ग्रोवर स्वीट है। उसके सामने वाला मकान है। ठीक है भैया 5 बोचरहाहूँवहीपे खुला हुआ।\n",
            "'आपने' not found.\n",
            "'तुम्हारी' not found.\n",
            "'hello' not found.\n",
            "Found 'हेलो' 1 times in the transcript.\n",
            "Occurrence of 'हेलो' - Start: 3.76s\n",
            "'40 95' not found.\n"
          ]
        }
      ],
      "source": [
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = \"\"\n",
        "\n",
        "audio_url = \"/content/917042143535_6673f94850c48178.mp3\"\n",
        "\n",
        "config = aai.TranscriptionConfig(\n",
        "    speaker_labels=True,\n",
        "    language_code='hi'\n",
        ")\n",
        "\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "transcript = transcriber.transcribe(audio_url, config)\n",
        "\n",
        "print(transcript.text)\n",
        "\n",
        "search_words = ['आपने', 'तुम्हारी', 'hello','हेलो','40 95']\n",
        "\n",
        "if hasattr(transcript, 'words') and transcript.words:\n",
        "    matches = transcript.word_search(search_words)\n",
        "    found_words = {match.text: match.count for match in matches}\n",
        "\n",
        "    for word in search_words:\n",
        "        if word in found_words:\n",
        "            print(f\"Found '{word}' {found_words[word]} times in the transcript.\")\n",
        "            for word_info in transcript.words:\n",
        "                if word_info.text == word:\n",
        "                    start_seconds = word_info.start / 1000.0\n",
        "                    print(f\"Occurrence of '{word}' - Start: {start_seconds:.2f}s\")\n",
        "        else:\n",
        "            print(f\"'{word}' not found.\")\n",
        "else:\n",
        "    print(\"Transcription failed or no words found in the transcript.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glG7OocLFo_I"
      },
      "source": [
        "# **Transcript using Whisper Large V3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8DCED7pyP_M1"
      },
      "outputs": [],
      "source": [
        "result1=\"अब अब अलो अलो अब बजा नहीं आ रहा था भाई तो भाई तो मेरा खड़ा है वहां पर आप किस तरफ पर आप थोड़ा बताओगे भाई यह जो तुम्हारी विशाल मेगामार्ट के आसपास बाइस नंबर गली है ना सीधे आदमे किलासपुरी चोक से चलते सीधे आदमे बाइस नंबर गली है अंदर जाकर पहले चोक वहीं पर कोरनर पर प्रेस वाला भी है पहले चोक पर कोरनर पर जाकर पहले चोक वहीं पर कोनर पर प्रेस वाला भी है पहले चोक पर इन कोरनर पर प्रेस वाला आपके सामने पर्शून की दुकान दिया और जो प्रेस वाला नहीं वह नहीं थोड़ा एक और आगे चला थोड़ा और आगे चले जाओ एक दूसरा चोक पड़ेगा उधर भी एक प्रेस वाला उधर खड़ा होगा वह आई उधर है घर आप सीधे-सीधे चले जाओ बाई बाई चालिस पिचानवे बाईक का नमबर है बोल दो माँ इक चालिस पिचानवे चालिस पिचानवे बाईक का नमबर है मेरी स्लिंडर ठीक है ठीक है ठीक\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wNTrxo31uC-",
        "outputId": "d40e915e-3ea2-4da9-f36c-4a400390b3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.9-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/328.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-1.35.9\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbqqbAJT1Zav",
        "outputId": "81036f68-7565-4b15-f9f9-dbfc094ec41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello. जी ये बिजली का आजा जाये शरूर। कहा पर है शरूर ये मकान आप था? ये उत्तमनगर में है शरूर. उत्तमनगर में ही कहा पर है? तारहाडि पर उत्तमणगर में काभी है. उत्तमण अगर में 28 बात नन्द शरूर के बाल गरोरर शूर। जब अब जब भरोल शूरी का मकान है ना दली कामे आउंड और szyरु करती है। पाँच उन्हें पूँच रहा हूँ। आज़ो बे आज़ो खुला हुए।\n",
            "Hello 4.44\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_API_KEY = \"\"\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "audio_file = open(\"/content/917042143535_6673f94850c48178.mp3\", \"rb\")\n",
        "\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    file=audio_file,\n",
        "    model=\"whisper-1\",\n",
        "    response_format=\"verbose_json\",\n",
        "    timestamp_granularities=[\"word\"]\n",
        ")\n",
        "\n",
        "audio_file.close()\n",
        "result=transcript.text\n",
        "print(result)\n",
        "search_words = ['कनेक्शन', 'वहाँ',\"Hello\"]\n",
        "\n",
        "for i in transcript.words:\n",
        "  if i['word'] in search_words:\n",
        "    print(f\"{i['word']} {i['start']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "639eb1kj42Dz"
      },
      "source": [
        "# **Text Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr7lR8a_40d7",
        "outputId": "315907d9-8868-45d4-e095-63b2c75108b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Sentiment: positive\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "classifier = joblib.load('svm_classifier.joblib')\n",
        "vectorizer = joblib.load('tfidf_vectorizer.joblib')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "    text_tfidf = vectorizer.transform([preprocessed_text])\n",
        "    prediction = classifier.predict(text_tfidf)[0]\n",
        "    return prediction\n",
        "\n",
        "input_text = result1 # or transcript.text for assemblyAI or result for WhisperAI or result1 for WhisperAI demo\n",
        "predicted_sentiment = predict_sentiment(input_text)\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
